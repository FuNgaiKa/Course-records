**课程设计报告**

通过学习page rank的基础知识，以及分布式map reduce的思想，了解了该算法在社交、搜索影响力评估上的重要作用。

然后利用kaggle中关于希拉里在2015年竞选总统期间的邮件往来数据集，利用page rank算法以及python中网络图以及建模的包NetworkX，完成对希拉里的人际关系中与各位人士的亲密程度分析。

获取到实验数据之后，首先对数据进行标准化，进行数据清洗以及对数据中的各种特征进行选择。容易看出，在一封信中我们需要的是发信人和收信人的信息。它代表的是page rank算法中的入链以及出链。

然后计算各类人物的PR值，然后通过反复迭代，得到一个收敛的最终PR值。然后转换成可视化的图。由于人物个数比较多，所以需要设置一个PR值得阈值，防止最终的图的节点过多。

由于数据量比较小，只有26M，因此单机版page rank可以完成。若数据量比较大，在100M或者1G的量级上，则需要通过map reduce思想来进行分布式的并行计算，然后进行合并。

可以分块通过哈希来计算每块中的人的PR值，然后在reduce阶段进行归并。由于预处理阶段已经将可能存在的人物的别名进行处理，因此不存在同一个人因为不同名字而被哈希得到两个PR值的情况。

需要注意的是，map reduce在某些程度上是比spark要慢的。虽然它们的计算都发生在内存中，但是map reduce在map之后通常需要将中间结果写入磁盘，而saprk则不需要。

同时，map reduce在map之后的shuffle中会进行不可避免的排序，因此耗费了一定的时间。



**readme**

预处理阶段：除了加载文件之外，还有针对文件的别名进行转换。另外一个函数则是利用NetworkX包来通过分别绘制节点和边来画出网络图。

挖掘阶段：通过设置边权重等于发邮件的次数，来计算每个节点（即人）的PR值，作为节点的page rank的属性。

最后通过阈值筛选之后，画出人物关系网络图。细节的说明已在注释中。



（记得有运行后的图片）

可以混几张hadoop的截图